{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c4d95b5",
   "metadata": {},
   "source": [
    "# Automated Meeting Analysis System Proof-of-Concept\n",
    "\n",
    "This notebook provides a complete proof-of-concept for an Automated Meeting Analysis System. It includes the following functionalities:\n",
    "\n",
    "- **Audio Transcription:** Converts a meeting audio file into text using speech recognition.\n",
    "- **(Optional) Speaker Diarization:** Placeholder for speaker separation (can be integrated with tools like `pyannote.audio`).\n",
    "- **Transcript Summarization:** Generates a concise summary using transformer models.\n",
    "- **Keyword Extraction:** Extracts the top keywords from the meeting transcript.\n",
    "- **Sentiment Analysis:** Analyzes the overall sentiment of the conversation.\n",
    "\n",
    "You can extend or customize each section for your project needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9b2f3a",
   "metadata": {},
   "source": [
    "## 1. Setup and Import Libraries\n",
    "\n",
    "This section imports the required libraries. Make sure to install these dependencies using pip:\n",
    "\n",
    "```bash\n",
    "pip install SpeechRecognition transformers nltk\n",
    "# Optionally, for speaker diarization:\n",
    "# pip install pyannote.audio\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5834af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import speech_recognition as sr\n",
    "from transformers import pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean and normalize text for keyword extraction.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "print('Setup complete: Libraries imported and resources downloaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f0dbd0",
   "metadata": {},
   "source": [
    "## 2. Audio Transcription\n",
    "\n",
    "This cell transcribes the meeting audio. Place your meeting audio file (in WAV format) in the same directory as the notebook and name it `meeting_audio.wav`. If the audio file is in another format or has a different name, adjust the `audio_file` variable accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c6e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the speech recognizer\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Set the audio file path\n",
    "audio_file = 'meeting_audio.wav'\n",
    "\n",
    "transcript = \"\"\n",
    "\n",
    "if os.path.exists(audio_file):\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        print('Reading audio file...')\n",
    "        audio = r.record(source)\n",
    "    try:\n",
    "        transcript = r.recognize_google(audio)\n",
    "        print('Transcription complete:')\n",
    "        print(transcript)\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Error: Speech Recognition could not understand the audio.\")\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Error: Could not request results; {e}\")\n",
    "else:\n",
    "    print(f\"Error: Audio file '{audio_file}' not found. Please add your audio file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a7c6fa",
   "metadata": {},
   "source": [
    "## 3. (Optional) Speaker Diarization\n",
    "\n",
    "For a complete meeting analysis, separating speakers is beneficial. This section is a placeholder where you can integrate a speaker diarization tool such as [pyannote.audio](https://github.com/pyannote/pyannote-audio). \n",
    "\n",
    "For demonstration purposes, we assume the transcript is from a single speaker. If you integrate diarization, you could split the transcript by speaker and analyze each segment separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a6c0a4",
   "metadata": {},
   "source": [
    "## 4. Transcript Summarization\n",
    "\n",
    "Using Hugging Face's Transformers summarization pipeline, we create a brief summary of the meeting transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2d7a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "if transcript:\n",
    "    summarizer = pipeline(\"summarization\")\n",
    "    # Adjust max_length and min_length parameters as needed\n",
    "    summary = summarizer(transcript, max_length=130, min_length=30, do_sample=False)\n",
    "    print(\"\\nMeeting Summary:\")\n",
    "    print(summary[0]['summary_text'])\n",
    "else:\n",
    "    print(\"Skipping summarization: No transcript available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b01e6e3",
   "metadata": {},
   "source": [
    "## 5. Keyword Extraction\n",
    "\n",
    "This cell extracts keywords by cleaning the transcript, removing stopwords, and calculating the frequency of remaining words. The top 5 words are displayed as keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c4f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "if transcript:\n",
    "    text_clean = clean_text(transcript)\n",
    "    words = text_clean.split()\n",
    "\n",
    "    # Remove stopwords\n",
    "    filtered_words = [word for word in words if word not in stopwords.words('english')]\n",
    "\n",
    "    # Count word frequencies\n",
    "    word_freq = Counter(filtered_words)\n",
    "    keywords = word_freq.most_common(5)\n",
    "    \n",
    "    print(\"\\nTop Keywords:\")\n",
    "    for word, freq in keywords:\n",
    "        print(f\"{word}: {freq}\")\n",
    "else:\n",
    "    print(\"Skipping keyword extraction: No transcript available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ab4eec",
   "metadata": {},
   "source": [
    "## 6. Sentiment Analysis\n",
    "\n",
    "Using another Hugging Face pipeline, we analyze the overall sentiment of the meeting conversation. This can provide insights into the mood or tone of the discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7e3f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if transcript:\n",
    "    sentiment_analyzer = pipeline('sentiment-analysis')\n",
    "    sentiment = sentiment_analyzer(transcript)\n",
    "    print(\"\\nSentiment Analysis:\")\n",
    "    print(sentiment)\n",
    "else:\n",
    "    print(\"Skipping sentiment analysis: No transcript available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5400fa",
   "metadata": {},
   "source": [
    "## 7. Final Thoughts\n",
    "\n",
    "This proof-of-concept demonstrates how to automatically process and analyze a meeting recording. You can further enhance the project by:\n",
    "\n",
    "- Integrating speaker diarization to separate speakers and perform per-speaker analysis.\n",
    "- Adding more advanced NLP analytics (such as topic modeling or action item extraction).\n",
    "- Creating a dashboard to visualize insights such as sentiment over time.\n",
    "\n",
    "Feel free to extend this notebook to meet the full requirements of your project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
